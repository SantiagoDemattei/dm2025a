{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0cEmzeUKFkPh"
   },
   "source": [
    "# Tarea para el Hogar 04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nSICPpyTGQmC"
   },
   "source": [
    "Esta Tarea para el Hogar 02 se entrega el final de la cuarta clase\n",
    "<br> se espera de usted que intente avanzar con los desafios propuestos y que los traiga terminados para la Clase 05 que será el viernes 01-agosto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DenyKXkiJ5JN"
   },
   "source": [
    "##  1. Cazatalentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l-K2_ZsZGrVD"
   },
   "source": [
    "En la Clase 03 nos hemos enfrentado a  \"La Maldicion del Ganandor\",  elegir el modelo con el mejor puntaje simple no suele ser la mejor estrategia.\n",
    "<br> Lea y ejecute el notebook  **src/CazaTalentos/CazaTalentos.ipynb**\n",
    "<br> en caso de interesarle, participe del Desafío Ordenamiento  que vence el sábado 02 de agosto a las 19:00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9GkTOk5J9t3"
   },
   "source": [
    "## 2. Hiperparámetros del LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VmEFy0ukKL5T"
   },
   "source": [
    "Los objetivos de esta tarea son:\n",
    "\n",
    "\n",
    "*   Aumentar la rentabilidad de la campaña de marketing de retención proactiva de clientes.\n",
    "*   Generar un mejor modelo optimizando sus hiperparámetros\n",
    "*   Conceptual : investigar los mas relevantes hiperparámetros de LightGBM\n",
    "*   Familiarizarse con la Bayesian Optimization, sus largos tiempos de corrida y opciones para reducirlos\n",
    "*   Familiarizarse con el uso de máquinas virtuales de Google Colab\n",
    "*   Ver un pipeline completo de optimización de hiperparámetros y puesta en producción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5yvlS6JQLRMd"
   },
   "source": [
    "LightGBM cuenta con mas de 60 hiperparámetros, siendo posible utilizar 40 al mismo tiempo, aunque no razonable.\n",
    "<br> La documentación oficial de los hiperparámetros de LightGBM es  https://lightgbm.readthedocs.io/en/latest/Parameters.html#core-parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eydI4YNAsFaf"
   },
   "source": [
    "Se lo alerta sobre que una Optimizacion Bayesiana lleva varias horas de corrida, y usted deberá correr VARIAS optimizaciones para descubrir cuales parámetros conviene optimizar.\n",
    "<br> A pesar que la próxima clase es recien en viernes 01 de agosto, inicie la tarea con tiempo, aprenda a planificar estratégicamente sus corridas como un@ científ@  de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzU4S0SeMcpp"
   },
   "source": [
    "Es necesario investigar cuales son los hiperparámetros de LightGBM que vale la pena optimizar en una Bayesian Optimization, ya que los realmente utiles son apenas un reducido subconjunto.\n",
    "<br>Usted deberá investigar cuales son los hiperparámetros mas relevantes de LightGBM, su primer alternativa es preguntándole a su amigo con capacidades especiales ChatGPT o sus endogámicos familiares Claude, DeepSeek, Gemini, Grok, etc\n",
    "<br> La segunda alternativa es la propia documentación de LightGBM  https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LNptUgI_NWWG"
   },
   "source": [
    "Adicionalmente podra buscar información como la que proveen esta diminuta muestra aleatoria de artículos ligeros:\n",
    "*  https://medium.com/@sarahzouinina/a-deep-dive-into-lightgbm-how-to-choose-and-tune-parameters-7c584945842e\n",
    "*  https://www.kaggle.com/code/somang1418/tuning-hyperparameters-under-10-minutes-lgbm\n",
    "*  https://towardsdatascience.com/beginners-guide-to-the-must-know-lightgbm-hyperparameters-a0005a812702/\n",
    "\n",
    "\n",
    "<br>  La muestra anterior se brinda a modo de ejemplo, usted deberá buscar muuuuchas  fuentes adicionales de información\n",
    "<br> Tenga presente que LightGBM es el estado del arte en modelado predictivo para datasets estructurado, que son el 90% del trabajo del 95% de los Data Scientists en Argentina."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WpUThBojODyK"
   },
   "source": [
    "El desafío de esta tarea es:\n",
    "* Qué hiperparparámetros conviene optimizar?  Las recomendaciones de los artículos ligeros es siempre sensata?  Sus autores realmente hicieron experimentos o son siemplemente escritores de entretenimiento carente de base científica?\n",
    "* Elegidos los hiperparámetros, cual es el  <desde, hasta> que se debe utilizar en la Bayesian Optimization ?\n",
    "* Realmente vale la pena optimizar 10 o 16 hiperparámetros al mismo tiempo ?  No resulta contraproducente una búsqueda en un espacio de tal alta dimensionalidad ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PX0qg_c0yqob"
   },
   "source": [
    "#### 2.1  Seteo del ambiente en Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NGY7H9xza7Zr"
   },
   "source": [
    "Esta parte se debe correr con el runtime en Python3\n",
    "<br>Ir al menu, Runtime -> Change Runtime Type -> Runtime type ->  **Python 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7PupIBNba7Zr"
   },
   "source": [
    "Conectar la virtual machine donde esta corriendo Google Colab con el  Google Drive, para poder tener persistencia de archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9LpZCst5a7Zs"
   },
   "outputs": [],
   "source": [
    "# primero establecer el Runtime de Python 3\n",
    "from google.colab import drive\n",
    "drive.mount('/content/.drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JYC_F-wla7Zs"
   },
   "source": [
    "Para correr la siguiente celda es fundamental en Arranque en Frio haber copiado el archivo kaggle.json al Google Drive, en la carpeta indicada en el instructivo\n",
    "\n",
    "<br>los siguientes comando estan en shell script de Linux\n",
    "*   Crear las carpetas en el Google Drive\n",
    "*   \"instalar\" el archivo kaggle.json desde el Google Drive a la virtual machine para que pueda ser utilizado por la libreria  kaggle de Python\n",
    "*   Bajar el  **dataset_pequeno**  al  Google Drive  y tambien al disco local de la virtual machine que esta corriendo Google Colab\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XWLelftXa7Zt"
   },
   "outputs": [],
   "source": [
    "%%shell\n",
    "\n",
    "mkdir -p \"/content/.drive/My Drive/dm\"\n",
    "mkdir -p \"/content/buckets\"\n",
    "ln -s \"/content/.drive/My Drive/dm\" /content/buckets/b1\n",
    "\n",
    "mkdir -p ~/.kaggle\n",
    "cp /content/buckets/b1/kaggle/kaggle.json  ~/.kaggle\n",
    "chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "\n",
    "mkdir -p /content/buckets/b1/exp\n",
    "mkdir -p /content/buckets/b1/datasets\n",
    "mkdir -p /content/datasets\n",
    "\n",
    "\n",
    "\n",
    "archivo_origen=\"https://storage.googleapis.com/open-courses/itba2025-8d0a/dataset_pequeno.csv\"\n",
    "archivo_destino=\"/content/datasets/dataset_pequeno.csv\"\n",
    "archivo_destino_bucket=\"/content/buckets/b1/datasets/dataset_pequeno.csv\"\n",
    "\n",
    "if ! test -f $archivo_destino_bucket; then\n",
    "  wget  $archivo_origen  -O $archivo_destino_bucket\n",
    "fi\n",
    "\n",
    "\n",
    "if ! test -f $archivo_destino; then\n",
    "  cp  $archivo_destino_bucket  $archivo_destino\n",
    "fi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSKhZRToy2F7"
   },
   "source": [
    "### 2.2 Optimizacion Hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2kwPpHAtSmix"
   },
   "source": [
    "Esta parte se debe correr con el runtime en lenguaje R Ir al menu, Runtime -> Change Runtime Type -> Runtime type -> R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xp4-Bj3aYI8d"
   },
   "source": [
    "### 2.2.1 Inicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zy8YTZfESxeJ"
   },
   "source": [
    "limpio el ambiente de R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gBq__iAdQliq"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Thu Jul 24 20:27:21 2025'"
      ],
      "text/latex": [
       "'Thu Jul 24 20:27:21 2025'"
      ],
      "text/markdown": [
       "'Thu Jul 24 20:27:21 2025'"
      ],
      "text/plain": [
       "[1] \"Thu Jul 24 20:27:21 2025\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "format(Sys.time(), \"%a %b %d %X %Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7rdVrBojS1IV"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 2 × 6 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Ncells</th><td> 656930</td><td>35.1</td><td>1439377</td><td>76.9</td><td>1431363</td><td>76.5</td></tr>\n",
       "\t<tr><th scope=row>Vcells</th><td>1224911</td><td> 9.4</td><td>8388608</td><td>64.0</td><td>1924961</td><td>14.7</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 6 of type dbl\n",
       "\\begin{tabular}{r|llllll}\n",
       "  & used & (Mb) & gc trigger & (Mb) & max used & (Mb)\\\\\n",
       "\\hline\n",
       "\tNcells &  656930 & 35.1 & 1439377 & 76.9 & 1431363 & 76.5\\\\\n",
       "\tVcells & 1224911 &  9.4 & 8388608 & 64.0 & 1924961 & 14.7\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 6 of type dbl\n",
       "\n",
       "| <!--/--> | used | (Mb) | gc trigger | (Mb) | max used | (Mb) |\n",
       "|---|---|---|---|---|---|---|\n",
       "| Ncells |  656930 | 35.1 | 1439377 | 76.9 | 1431363 | 76.5 |\n",
       "| Vcells | 1224911 |  9.4 | 8388608 | 64.0 | 1924961 | 14.7 |\n",
       "\n"
      ],
      "text/plain": [
       "       used    (Mb) gc trigger (Mb) max used (Mb)\n",
       "Ncells  656930 35.1 1439377    76.9 1431363  76.5\n",
       "Vcells 1224911  9.4 8388608    64.0 1924961  14.7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# limpio la memoria\n",
    "rm(list=ls(all.names=TRUE)) # remove all objects\n",
    "gc(full=TRUE, verbose=FALSE) # garbage collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuPfQ7ksjwW3"
   },
   "source": [
    "### 2.2.2 Carga de Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lVyxLaJ1j1J_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: data.table\n",
      "\n",
      "Loading required package: parallel\n",
      "\n",
      "Loading required package: primes\n",
      "\n",
      "Loading required package: rlist\n",
      "\n",
      "Loading required package: yaml\n",
      "\n",
      "Loading required package: lightgbm\n",
      "\n",
      "Loading required package: DiceKriging\n",
      "\n",
      "Loading required package: mlrMBO\n",
      "\n",
      "Loading required package: mlr\n",
      "\n",
      "Loading required package: ParamHelpers\n",
      "\n",
      "Loading required package: smoof\n",
      "\n",
      "Loading required package: checkmate\n",
      "\n",
      "\n",
      "Attaching package: ‘checkmate’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:DiceKriging’:\n",
      "\n",
      "    checkNames\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cargo las librerias que necesito\n",
    "require(\"data.table\")\n",
    "require(\"parallel\")\n",
    "\n",
    "if( !require(\"primes\") ) install.packages(\"primes\")\n",
    "require(\"primes\")\n",
    "\n",
    "if( !require(\"utils\") ) install.packages(\"utils\")\n",
    "require(\"utils\")\n",
    "\n",
    "if( !require(\"rlist\") ) install.packages(\"rlist\")\n",
    "require(\"rlist\")\n",
    "\n",
    "if( !require(\"yaml\")) install.packages(\"yaml\")\n",
    "require(\"yaml\")\n",
    "\n",
    "if( !require(\"lightgbm\") ) install.packages(\"lightgbm\")\n",
    "require(\"lightgbm\")\n",
    "\n",
    "if( !require(\"DiceKriging\") ) install.packages(\"DiceKriging\")\n",
    "require(\"DiceKriging\")\n",
    "\n",
    "if( !require(\"mlrMBO\") ) install.packages(\"mlrMBO\")\n",
    "require(\"mlrMBO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iz-6Qt6BUaA3"
   },
   "source": [
    "### 2.2.3 Definicion de Parametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cOdlKd7lUm2I"
   },
   "source": [
    "aqui debe cargar SU semilla primigenia\n",
    "<br>recuerde cambiar el numero de experimento en cada corrida nueva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ASYkebOu2mF6"
   },
   "outputs": [],
   "source": [
    "PARAM <- list()\n",
    "PARAM$experimento <- 4948\n",
    "PARAM$semilla_primigenia <- 100129\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ezOhQdbA293o"
   },
   "outputs": [],
   "source": [
    "PARAM$kaggle$competencia <- \"data-mining-analista-sr-2025-a\"\n",
    "PARAM$kaggle$cortes <- seq(10000, 12000, by= 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "jtB0Lub42rHO"
   },
   "outputs": [],
   "source": [
    "# un undersampling de 0.1  toma solo el 10% de los CONTINUA\n",
    "# undersampling de 1.0  implica tomar TODOS los datos\n",
    "\n",
    "PARAM$trainingstrategy$undersampling <- 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "OFxm-xiNUOJX"
   },
   "outputs": [],
   "source": [
    "# Parametros LightGBM\n",
    "\n",
    "PARAM$hyperparametertuning$xval_folds <- 5\n",
    "\n",
    "# parametros fijos del LightGBM que se pisaran con la parte variable de la BO\n",
    "PARAM$lgbm$param_fijos <-  list(\n",
    "  boosting= \"gbdt\", # puede ir  dart  , ni pruebe random_forest\n",
    "  objective= \"binary\",\n",
    "  metric= \"auc\",\n",
    "  first_metric_only= FALSE,\n",
    "  boost_from_average= TRUE,\n",
    "  feature_pre_filter= FALSE,\n",
    "  force_row_wise= TRUE, # para reducir warnings\n",
    "  verbosity= -100,\n",
    "\n",
    "  seed= PARAM$semilla_primigenia,\n",
    "\n",
    "  max_depth= -1L, # -1 significa no limitar,  por ahora lo dejo fijo\n",
    "  min_gain_to_split= 0, # min_gain_to_split >= 0\n",
    "  min_sum_hessian_in_leaf= 0.001, #  min_sum_hessian_in_leaf >= 0.0\n",
    "  lambda_l1= 0.0, # lambda_l1 >= 0.0\n",
    "  lambda_l2= 0.0, # lambda_l2 >= 0.0\n",
    "  max_bin= 31L, # lo debo dejar fijo, no participa de la BO\n",
    "\n",
    "  bagging_fraction= 1.0, # 0.0 < bagging_fraction <= 1.0\n",
    "  pos_bagging_fraction= 1.0, # 0.0 < pos_bagging_fraction <= 1.0\n",
    "  neg_bagging_fraction= 1.0, # 0.0 < neg_bagging_fraction <= 1.0\n",
    "  is_unbalance= FALSE, #\n",
    "  scale_pos_weight= 1.0, # scale_pos_weight > 0.0\n",
    "\n",
    "  drop_rate= 0.1, # 0.0 < neg_bagging_fraction <= 1.0\n",
    "  max_drop= 50, # <=0 means no limit\n",
    "  skip_drop= 0.5, # 0.0 <= skip_drop <= 1.0\n",
    "\n",
    "  extra_trees= FALSE,\n",
    "\n",
    "  num_iterations= 1200,\n",
    "  learning_rate= 0.02,\n",
    "  feature_fraction= 0.5,\n",
    "  num_leaves= 750,\n",
    "  min_data_in_leaf= 5000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D5Yj-JV4yvOt"
   },
   "source": [
    "Aqui se definen los hiperparámetros de LightGBM que participan de la Bayesian Optimization\n",
    "<br> si es un numero entero debe ir  makeIntegerParam\n",
    "<br> si es un numero real (con decimales) debe ir  makeNumericParam\n",
    "<br> es muy importante leer cuales son un lower y upper  permitidos y ademas razonables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "jENpR26ZyuS8"
   },
   "outputs": [],
   "source": [
    "# Aqui se cargan los bordes de los hiperparametros de la BO\n",
    "PARAM$hypeparametertuning$hs <- makeParamSet(\n",
    "  makeIntegerParam(\"num_iterations\", lower = 650L, upper = 1100L),\n",
    "  makeNumericParam(\"learning_rate\", lower = 0.008, upper = 0.025),\n",
    "  makeNumericParam(\"feature_fraction\", lower = 0.30, upper = 0.60),\n",
    "  makeIntegerParam(\"min_data_in_leaf\", lower = 200L, upper = 500L),\n",
    "  makeIntegerParam(\"num_leaves\", lower = 130L, upper = 280L),\n",
    "  makeIntegerParam(\"max_depth\", lower = 8L, upper = 12L),\n",
    "  makeNumericParam(\"lambda_l1\", lower = 2.0, upper = 5.0),\n",
    "  makeNumericParam(\"lambda_l2\", lower = 2.5, upper = 4.5),\n",
    "  makeNumericParam(\"min_gain_to_split\", lower = 0.05, upper = 0.20),\n",
    "  makeNumericParam(\"bagging_fraction\", lower = 0.80, upper = 0.95)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_RPFUb3zMoW"
   },
   "source": [
    "A mayor cantidad de hiperparámetros, se debe aumentar las iteraciones de la Bayesian Optimization\n",
    "<br> 30 es un valor muy tacaño, pero corre rápido\n",
    "<br> deberia partir de 50, alcanzando los 100 si se dispone de tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "q5Rd3pnbzSiG"
   },
   "outputs": [],
   "source": [
    "PARAM$hyperparametertuning$iteraciones <- 100 # iteraciones bayesianas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4RWZXL1VZjMI"
   },
   "source": [
    "### 2.2.4  Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "j3toG9-lZm4K"
   },
   "outputs": [],
   "source": [
    "# carpeta de trabajo\n",
    "\n",
    "setwd(\"/content/buckets/b1/exp\")\n",
    "experimento_folder <- paste0(\"HT\", PARAM$experimento)\n",
    "dir.create(experimento_folder, showWarnings=FALSE)\n",
    "setwd( paste0(\"/content/buckets/b1/exp/\", experimento_folder ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "FM3lxKoLZ643"
   },
   "outputs": [],
   "source": [
    "# lectura del dataset\n",
    "\n",
    "dataset <- fread(\"/content/datasets/dataset_pequeno.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "OsJ-91UeZ-I_"
   },
   "outputs": [],
   "source": [
    "dataset_train <- dataset[foto_mes %in% c(202107)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "vrWE7BE0aB2J"
   },
   "outputs": [],
   "source": [
    "# paso la clase a binaria que tome valores {0,1}  enteros\n",
    "#  BAJA+1 y BAJA+2  son  1,   CONTINUA es 0\n",
    "\n",
    "dataset_train[,\n",
    "  clase01 := ifelse(clase_ternaria %in% c(\"BAJA+2\",\"BAJA+1\"), 1L, 0L)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "jP7YlQBnaW6W"
   },
   "outputs": [],
   "source": [
    "# defino los datos que forma parte del training\n",
    "# aqui se hace el undersampling de los CONTINUA\n",
    "# notar que para esto utilizo la SEGUNDA semilla\n",
    "\n",
    "set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")\n",
    "dataset_train[, azar := runif(nrow(dataset_train))]\n",
    "dataset_train[, training := 0L]\n",
    "\n",
    "dataset_train[\n",
    "  foto_mes %in% c(202107) &\n",
    "    (azar <= PARAM$trainingstrategy$undersampling | clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\")),\n",
    "  training := 1L\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "xElu4s5W4rX7"
   },
   "outputs": [],
   "source": [
    "# los campos que se van a utilizar\n",
    "\n",
    "campos_buenos <- setdiff(\n",
    "  colnames(dataset_train),\n",
    "  c(\"clase_ternaria\", \"clase01\", \"azar\", \"training\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "PppMHcGYaaol"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "83679"
      ],
      "text/latex": [
       "83679"
      ],
      "text/markdown": [
       "83679"
      ],
      "text/plain": [
       "[1] 83679"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "154"
      ],
      "text/latex": [
       "154"
      ],
      "text/markdown": [
       "154"
      ],
      "text/plain": [
       "[1] 154"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dejo los datos en el formato que necesita LightGBM\n",
    "\n",
    "dtrain <- lgb.Dataset(\n",
    "  data= data.matrix(dataset_train[training == 1L, campos_buenos, with= FALSE]),\n",
    "  label= dataset_train[training == 1L, clase01],\n",
    "  free_raw_data= FALSE\n",
    ")\n",
    "\n",
    "nrow(dtrain)\n",
    "ncol(dtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ta-EkOu3cphF"
   },
   "source": [
    "2.2.5 Configuracion Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "cjgfurjdfiXb"
   },
   "outputs": [],
   "source": [
    "# En el argumento x llegan los parmaetros de la bayesiana\n",
    "#  devuelve la AUC en cross validation del modelo entrenado\n",
    "\n",
    "EstimarGanancia_AUC_lightgbm <- function(x) {\n",
    "\n",
    "  # x pisa (o agrega) a param_fijos\n",
    "  param_completo <- modifyList(PARAM$lgbm$param_fijos, x)\n",
    "\n",
    "  # entreno LightGBM\n",
    "  modelocv <- lgb.cv(\n",
    "    data= dtrain,\n",
    "    nfold= PARAM$hyperparametertuning$xval_folds,\n",
    "    stratified= TRUE,\n",
    "    param= param_completo\n",
    "  )\n",
    "\n",
    "  # obtengo la ganancia\n",
    "  AUC <- modelocv$best_score\n",
    "\n",
    "  # hago espacio en la memoria\n",
    "  rm(modelocv)\n",
    "  gc(full= TRUE, verbose= FALSE)\n",
    "\n",
    "  message(format(Sys.time(), \"%a %b %d %X %Y\"), \" AUC \", AUC)\n",
    "\n",
    "  return(AUC)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "WLi_o1hocvN-"
   },
   "outputs": [],
   "source": [
    "# Aqui comienza la configuracion de la Bayesian Optimization\n",
    "\n",
    "# en este archivo quedan la evolucion binaria de la BO\n",
    "kbayesiana <- \"bayesiana.RDATA\"\n",
    "\n",
    "funcion_optimizar <- EstimarGanancia_AUC_lightgbm # la funcion que voy a maximizar\n",
    "\n",
    "configureMlr(show.learner.output= FALSE)\n",
    "\n",
    "# configuro la busqueda bayesiana,  los hiperparametros que se van a optimizar\n",
    "# por favor, no desesperarse por lo complejo\n",
    "\n",
    "obj.fun <- makeSingleObjectiveFunction(\n",
    "  fn= funcion_optimizar, # la funcion que voy a maximizar\n",
    "  minimize= FALSE, # estoy Maximizando la ganancia\n",
    "  noisy= TRUE,\n",
    "  par.set= PARAM$hypeparametertuning$hs, # definido al comienzo del programa\n",
    "  has.simple.signature= FALSE # paso los parametros en una lista\n",
    ")\n",
    "\n",
    "# cada 600 segundos guardo el resultado intermedio\n",
    "ctrl <- makeMBOControl(\n",
    "  save.on.disk.at.time= 600, # se graba cada 600 segundos\n",
    "  save.file.path= kbayesiana\n",
    ") # se graba cada 600 segundos\n",
    "\n",
    "# indico la cantidad de iteraciones que va a tener la Bayesian Optimization\n",
    "ctrl <- setMBOControlTermination(\n",
    "  ctrl,\n",
    "  iters= PARAM$hyperparametertuning$iteraciones\n",
    ") # cantidad de iteraciones\n",
    "\n",
    "# defino el método estandar para la creacion de los puntos iniciales,\n",
    "# los \"No Inteligentes\"\n",
    "ctrl <- setMBOControlInfill(ctrl, crit= makeMBOInfillCritEI())\n",
    "\n",
    "# establezco la funcion que busca el maximo\n",
    "surr.km <- makeLearner(\n",
    "  \"regr.km\",\n",
    "  predict.type= \"se\",\n",
    "  covtype= \"matern3_2\",\n",
    "  control= list(trace= TRUE)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_uUeVo5pc4zc"
   },
   "source": [
    "2.2.6 Corrida Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "RcABNaKGciaz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing y column(s) for design. Not provided.\n",
      "\n",
      "Thu Jul 24 20:33:13 2025 AUC 0.931040853044577\n",
      "\n",
      "Thu Jul 24 20:34:10 2025 AUC 0.931054432146651\n",
      "\n",
      "Thu Jul 24 20:35:00 2025 AUC 0.930751074348758\n",
      "\n",
      "Thu Jul 24 20:35:48 2025 AUC 0.930454513869686\n",
      "\n",
      "Thu Jul 24 20:36:37 2025 AUC 0.930480548607735\n",
      "\n",
      "Thu Jul 24 20:37:41 2025 AUC 0.930641986272105\n",
      "\n",
      "Thu Jul 24 20:38:28 2025 AUC 0.930503107902952\n",
      "\n",
      "Thu Jul 24 20:39:15 2025 AUC 0.930117395704713\n",
      "\n",
      "Thu Jul 24 20:40:09 2025 AUC 0.931286700676455\n",
      "\n",
      "Thu Jul 24 20:41:03 2025 AUC 0.930938516000969\n",
      "\n",
      "Thu Jul 24 20:42:01 2025 AUC 0.930825748440468\n",
      "\n",
      "Thu Jul 24 20:42:41 2025 AUC 0.931013335335902\n",
      "\n",
      "Thu Jul 24 20:43:48 2025 AUC 0.931011670874674\n",
      "\n",
      "Thu Jul 24 20:44:53 2025 AUC 0.930591795880561\n",
      "\n",
      "Thu Jul 24 20:45:44 2025 AUC 0.931579669553934\n",
      "\n",
      "Thu Jul 24 20:46:43 2025 AUC 0.930479007148121\n",
      "\n",
      "Thu Jul 24 20:47:34 2025 AUC 0.93057357660226\n",
      "\n",
      "Thu Jul 24 20:48:35 2025 AUC 0.931815777693776\n",
      "\n",
      "Thu Jul 24 20:49:31 2025 AUC 0.930844345260085\n",
      "\n",
      "Thu Jul 24 20:50:17 2025 AUC 0.931084562867069\n",
      "\n",
      "Thu Jul 24 20:51:09 2025 AUC 0.93060980135879\n",
      "\n",
      "Thu Jul 24 20:52:03 2025 AUC 0.930142743117201\n",
      "\n",
      "Thu Jul 24 20:52:55 2025 AUC 0.930931011391536\n",
      "\n",
      "Thu Jul 24 20:53:52 2025 AUC 0.931078693522665\n",
      "\n",
      "Thu Jul 24 20:54:35 2025 AUC 0.931120719209722\n",
      "\n",
      "Thu Jul 24 20:55:47 2025 AUC 0.930226569199683\n",
      "\n",
      "Thu Jul 24 20:56:50 2025 AUC 0.930992162596892\n",
      "\n",
      "Thu Jul 24 20:57:35 2025 AUC 0.930449667098165\n",
      "\n",
      "Thu Jul 24 20:58:25 2025 AUC 0.931100224794775\n",
      "\n",
      "Thu Jul 24 20:59:11 2025 AUC 0.93147456256289\n",
      "\n",
      "Thu Jul 24 21:00:07 2025 AUC 0.931258770611859\n",
      "\n",
      "Thu Jul 24 21:01:15 2025 AUC 0.931103142884447\n",
      "\n",
      "Thu Jul 24 21:02:18 2025 AUC 0.93108554694266\n",
      "\n",
      "Thu Jul 24 21:03:02 2025 AUC 0.930015099207526\n",
      "\n",
      "Thu Jul 24 21:03:48 2025 AUC 0.929534448433597\n",
      "\n",
      "Thu Jul 24 21:04:30 2025 AUC 0.93142949019622\n",
      "\n",
      "Thu Jul 24 21:05:23 2025 AUC 0.930399350495318\n",
      "\n",
      "Thu Jul 24 21:06:20 2025 AUC 0.930617230269923\n",
      "\n",
      "Thu Jul 24 21:07:34 2025 AUC 0.930193855944575\n",
      "\n",
      "Thu Jul 24 21:08:19 2025 AUC 0.931162118103776\n",
      "\n",
      "[mbo] 0: num_iterations=937; learning_rate=0.0195; feature_fraction=0.326; min_data_in_leaf=209; num_leaves=199; max_depth=11; lambda_l1=4.61; lambda_l2=3.46; min_gain_to_split=0.171; bagging_fraction=0.881 : y = 0.931 : 53.2 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=815; learning_rate=0.0146; feature_fraction=0.504; min_data_in_leaf=429; num_leaves=211; max_depth=11; lambda_l1=3.59; lambda_l2=2.84; min_gain_to_split=0.169; bagging_fraction=0.872 : y = 0.931 : 57.1 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=830; learning_rate=0.0159; feature_fraction=0.562; min_data_in_leaf=312; num_leaves=167; max_depth=9; lambda_l1=4.54; lambda_l2=3.61; min_gain_to_split=0.183; bagging_fraction=0.865 : y = 0.931 : 49.1 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=820; learning_rate=0.0161; feature_fraction=0.36; min_data_in_leaf=352; num_leaves=146; max_depth=9; lambda_l1=3; lambda_l2=3.34; min_gain_to_split=0.0909; bagging_fraction=0.921 : y = 0.93 : 48.5 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=861; learning_rate=0.0211; feature_fraction=0.371; min_data_in_leaf=385; num_leaves=234; max_depth=10; lambda_l1=3.69; lambda_l2=3.44; min_gain_to_split=0.179; bagging_fraction=0.827 : y = 0.93 : 48.9 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=922; learning_rate=0.0167; feature_fraction=0.422; min_data_in_leaf=372; num_leaves=177; max_depth=11; lambda_l1=2.52; lambda_l2=4.09; min_gain_to_split=0.146; bagging_fraction=0.801 : y = 0.931 : 64.0 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=768; learning_rate=0.0101; feature_fraction=0.47; min_data_in_leaf=241; num_leaves=182; max_depth=8; lambda_l1=3.8; lambda_l2=3.25; min_gain_to_split=0.127; bagging_fraction=0.902 : y = 0.931 : 46.8 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=791; learning_rate=0.0088; feature_fraction=0.385; min_data_in_leaf=364; num_leaves=261; max_depth=9; lambda_l1=3.38; lambda_l2=3.01; min_gain_to_split=0.121; bagging_fraction=0.858 : y = 0.93 : 47.6 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=731; learning_rate=0.0176; feature_fraction=0.451; min_data_in_leaf=258; num_leaves=203; max_depth=12; lambda_l1=3.57; lambda_l2=2.61; min_gain_to_split=0.106; bagging_fraction=0.878 : y = 0.931 : 54.2 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=916; learning_rate=0.0223; feature_fraction=0.418; min_data_in_leaf=326; num_leaves=214; max_depth=10; lambda_l1=3.93; lambda_l2=3.87; min_gain_to_split=0.112; bagging_fraction=0.924 : y = 0.931 : 53.9 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=995; learning_rate=0.0152; feature_fraction=0.405; min_data_in_leaf=482; num_leaves=196; max_depth=8; lambda_l1=4.66; lambda_l2=2.52; min_gain_to_split=0.0989; bagging_fraction=0.932 : y = 0.931 : 57.8 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=650; learning_rate=0.0122; feature_fraction=0.493; min_data_in_leaf=452; num_leaves=171; max_depth=8; lambda_l1=3.07; lambda_l2=3.93; min_gain_to_split=0.137; bagging_fraction=0.943 : y = 0.931 : 40.1 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1050; learning_rate=0.0184; feature_fraction=0.446; min_data_in_leaf=378; num_leaves=229; max_depth=12; lambda_l1=3.17; lambda_l2=2.69; min_gain_to_split=0.115; bagging_fraction=0.899 : y = 0.931 : 66.9 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1008; learning_rate=0.00939; feature_fraction=0.598; min_data_in_leaf=298; num_leaves=280; max_depth=11; lambda_l1=3.49; lambda_l2=3.37; min_gain_to_split=0.133; bagging_fraction=0.822 : y = 0.931 : 64.4 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=753; learning_rate=0.0215; feature_fraction=0.532; min_data_in_leaf=460; num_leaves=249; max_depth=10; lambda_l1=2.26; lambda_l2=3.77; min_gain_to_split=0.0684; bagging_fraction=0.89 : y = 0.932 : 51.7 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=851; learning_rate=0.0171; feature_fraction=0.524; min_data_in_leaf=223; num_leaves=238; max_depth=9; lambda_l1=3.99; lambda_l2=3.09; min_gain_to_split=0.0587; bagging_fraction=0.89 : y = 0.93 : 59.0 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=727; learning_rate=0.0205; feature_fraction=0.487; min_data_in_leaf=231; num_leaves=160; max_depth=10; lambda_l1=2.56; lambda_l2=3.56; min_gain_to_split=0.143; bagging_fraction=0.844 : y = 0.931 : 51.1 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1011; learning_rate=0.0143; feature_fraction=0.334; min_data_in_leaf=350; num_leaves=192; max_depth=10; lambda_l1=4.12; lambda_l2=4.36; min_gain_to_split=0.0938; bagging_fraction=0.838 : y = 0.932 : 60.5 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=982; learning_rate=0.0198; feature_fraction=0.43; min_data_in_leaf=423; num_leaves=185; max_depth=11; lambda_l1=3.86; lambda_l2=4.45; min_gain_to_split=0.192; bagging_fraction=0.931 : y = 0.931 : 56.2 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=707; learning_rate=0.0135; feature_fraction=0.512; min_data_in_leaf=402; num_leaves=149; max_depth=10; lambda_l1=4.47; lambda_l2=3.71; min_gain_to_split=0.15; bagging_fraction=0.807 : y = 0.931 : 46.4 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=784; learning_rate=0.0219; feature_fraction=0.312; min_data_in_leaf=285; num_leaves=276; max_depth=12; lambda_l1=3.21; lambda_l2=2.77; min_gain_to_split=0.076; bagging_fraction=0.884 : y = 0.931 : 51.1 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=906; learning_rate=0.013; feature_fraction=0.304; min_data_in_leaf=341; num_leaves=245; max_depth=10; lambda_l1=2.38; lambda_l2=3.68; min_gain_to_split=0.16; bagging_fraction=0.91 : y = 0.93 : 54.2 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=952; learning_rate=0.0187; feature_fraction=0.348; min_data_in_leaf=281; num_leaves=208; max_depth=8; lambda_l1=4.38; lambda_l2=2.56; min_gain_to_split=0.152; bagging_fraction=0.851 : y = 0.931 : 52.1 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=957; learning_rate=0.0241; feature_fraction=0.48; min_data_in_leaf=403; num_leaves=136; max_depth=8; lambda_l1=3.31; lambda_l2=4.29; min_gain_to_split=0.104; bagging_fraction=0.834 : y = 0.931 : 57.0 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=801; learning_rate=0.0153; feature_fraction=0.343; min_data_in_leaf=467; num_leaves=257; max_depth=8; lambda_l1=2.16; lambda_l2=4.24; min_gain_to_split=0.0625; bagging_fraction=0.855 : y = 0.931 : 43.1 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1039; learning_rate=0.0099; feature_fraction=0.537; min_data_in_leaf=266; num_leaves=172; max_depth=11; lambda_l1=4.72; lambda_l2=3.22; min_gain_to_split=0.129; bagging_fraction=0.897 : y = 0.93 : 72.6 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=885; learning_rate=0.0107; feature_fraction=0.555; min_data_in_leaf=329; num_leaves=222; max_depth=11; lambda_l1=2.64; lambda_l2=3.81; min_gain_to_split=0.0566; bagging_fraction=0.947 : y = 0.931 : 62.3 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=691; learning_rate=0.018; feature_fraction=0.438; min_data_in_leaf=446; num_leaves=219; max_depth=10; lambda_l1=4.87; lambda_l2=4.34; min_gain_to_split=0.0506; bagging_fraction=0.863 : y = 0.93 : 45.1 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=701; learning_rate=0.0139; feature_fraction=0.502; min_data_in_leaf=416; num_leaves=272; max_depth=12; lambda_l1=2.35; lambda_l2=4.05; min_gain_to_split=0.156; bagging_fraction=0.81 : y = 0.931 : 50.6 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=868; learning_rate=0.0242; feature_fraction=0.589; min_data_in_leaf=294; num_leaves=266; max_depth=9; lambda_l1=2.04; lambda_l2=2.88; min_gain_to_split=0.166; bagging_fraction=0.846 : y = 0.931 : 46.2 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1067; learning_rate=0.0232; feature_fraction=0.575; min_data_in_leaf=478; num_leaves=139; max_depth=12; lambda_l1=4.78; lambda_l2=3.17; min_gain_to_split=0.0817; bagging_fraction=0.908 : y = 0.931 : 55.5 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1096; learning_rate=0.0123; feature_fraction=0.463; min_data_in_leaf=496; num_leaves=252; max_depth=9; lambda_l1=4.18; lambda_l2=3.14; min_gain_to_split=0.0792; bagging_fraction=0.812 : y = 0.931 : 67.9 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1030; learning_rate=0.0247; feature_fraction=0.394; min_data_in_leaf=248; num_leaves=187; max_depth=12; lambda_l1=2.84; lambda_l2=2.94; min_gain_to_split=0.0849; bagging_fraction=0.818 : y = 0.931 : 62.8 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1082; learning_rate=0.0227; feature_fraction=0.581; min_data_in_leaf=315; num_leaves=227; max_depth=8; lambda_l1=4.98; lambda_l2=3.51; min_gain_to_split=0.188; bagging_fraction=0.868 : y = 0.93 : 44.2 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=677; learning_rate=0.0117; feature_fraction=0.565; min_data_in_leaf=273; num_leaves=132; max_depth=11; lambda_l1=2.69; lambda_l2=4.14; min_gain_to_split=0.177; bagging_fraction=0.939 : y = 0.93 : 46.6 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=671; learning_rate=0.0234; feature_fraction=0.362; min_data_in_leaf=202; num_leaves=144; max_depth=9; lambda_l1=4.25; lambda_l2=4.17; min_gain_to_split=0.0966; bagging_fraction=0.914 : y = 0.931 : 41.3 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=888; learning_rate=0.0111; feature_fraction=0.316; min_data_in_leaf=488; num_leaves=154; max_depth=12; lambda_l1=4.07; lambda_l2=2.96; min_gain_to_split=0.193; bagging_fraction=0.83 : y = 0.93 : 53.5 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=971; learning_rate=0.00915; feature_fraction=0.378; min_data_in_leaf=219; num_leaves=156; max_depth=8; lambda_l1=2.77; lambda_l2=3.97; min_gain_to_split=0.0701; bagging_fraction=0.825 : y = 0.931 : 57.2 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1056; learning_rate=0.00823; feature_fraction=0.542; min_data_in_leaf=391; num_leaves=263; max_depth=12; lambda_l1=2.1; lambda_l2=4.47; min_gain_to_split=0.197; bagging_fraction=0.918 : y = 0.93 : 73.2 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=748; learning_rate=0.0202; feature_fraction=0.404; min_data_in_leaf=433; num_leaves=239; max_depth=9; lambda_l1=2.96; lambda_l2=2.72; min_gain_to_split=0.122; bagging_fraction=0.937 : y = 0.931 : 45.9 secs : initdesign\n",
      "\n",
      "Saved the current state after iteration 1 in the file bayesiana.RDATA.\n",
      "\n",
      "Thu Jul 24 21:09:27 2025 AUC 0.9313131061709\n",
      "\n",
      "[mbo] 1: num_iterations=985; learning_rate=0.0141; feature_fraction=0.391; min_data_in_leaf=452; num_leaves=193; max_depth=10; lambda_l1=4.33; lambda_l2=4.33; min_gain_to_split=0.0978; bagging_fraction=0.813 : y = 0.931 : 61.4 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:10:27 2025 AUC 0.931766722254682\n",
      "\n",
      "[mbo] 2: num_iterations=963; learning_rate=0.0143; feature_fraction=0.352; min_data_in_leaf=342; num_leaves=245; max_depth=10; lambda_l1=4.29; lambda_l2=4.36; min_gain_to_split=0.0889; bagging_fraction=0.85 : y = 0.932 : 58.6 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:11:25 2025 AUC 0.931431424340069\n",
      "\n",
      "[mbo] 3: num_iterations=942; learning_rate=0.0167; feature_fraction=0.329; min_data_in_leaf=304; num_leaves=164; max_depth=9; lambda_l1=4.31; lambda_l2=4.34; min_gain_to_split=0.0982; bagging_fraction=0.808 : y = 0.931 : 56.5 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:12:22 2025 AUC 0.931337582523873\n",
      "\n",
      "[mbo] 4: num_iterations=874; learning_rate=0.0149; feature_fraction=0.384; min_data_in_leaf=336; num_leaves=194; max_depth=10; lambda_l1=2.34; lambda_l2=4.37; min_gain_to_split=0.0924; bagging_fraction=0.851 : y = 0.931 : 56.2 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:13:27 2025 AUC 0.930522721123363\n",
      "\n",
      "[mbo] 5: num_iterations=1015; learning_rate=0.0102; feature_fraction=0.388; min_data_in_leaf=316; num_leaves=210; max_depth=9; lambda_l1=4.36; lambda_l2=4.36; min_gain_to_split=0.0912; bagging_fraction=0.894 : y = 0.931 : 63.9 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:14:30 2025 AUC 0.931567099474935\n",
      "\n",
      "[mbo] 6: num_iterations=982; learning_rate=0.0146; feature_fraction=0.348; min_data_in_leaf=314; num_leaves=215; max_depth=10; lambda_l1=4.46; lambda_l2=4.32; min_gain_to_split=0.089; bagging_fraction=0.833 : y = 0.932 : 61.6 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:15:35 2025 AUC 0.93021027532958\n",
      "\n",
      "[mbo] 7: num_iterations=972; learning_rate=0.0144; feature_fraction=0.565; min_data_in_leaf=357; num_leaves=229; max_depth=10; lambda_l1=4.03; lambda_l2=4.4; min_gain_to_split=0.0961; bagging_fraction=0.819 : y = 0.93 : 64.2 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:16:32 2025 AUC 0.931154906857442\n",
      "\n",
      "[mbo] 8: num_iterations=957; learning_rate=0.0146; feature_fraction=0.322; min_data_in_leaf=415; num_leaves=235; max_depth=9; lambda_l1=3.88; lambda_l2=4.38; min_gain_to_split=0.0761; bagging_fraction=0.883 : y = 0.931 : 55.1 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:17:35 2025 AUC 0.930296944958698\n",
      "\n",
      "[mbo] 9: num_iterations=993; learning_rate=0.0139; feature_fraction=0.335; min_data_in_leaf=355; num_leaves=181; max_depth=10; lambda_l1=4.24; lambda_l2=3.93; min_gain_to_split=0.0935; bagging_fraction=0.852 : y = 0.93 : 62.1 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:18:39 2025 AUC 0.931584670588616\n",
      "\n",
      "[mbo] 10: num_iterations=1050; learning_rate=0.0128; feature_fraction=0.323; min_data_in_leaf=349; num_leaves=171; max_depth=10; lambda_l1=4.81; lambda_l2=4.02; min_gain_to_split=0.0937; bagging_fraction=0.914 : y = 0.932 : 62.3 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 11 in the file bayesiana.RDATA.\n",
      "\n",
      "Thu Jul 24 21:19:41 2025 AUC 0.931866202887996\n",
      "\n",
      "[mbo] 11: num_iterations=961; learning_rate=0.0155; feature_fraction=0.338; min_data_in_leaf=362; num_leaves=233; max_depth=10; lambda_l1=3.47; lambda_l2=4.36; min_gain_to_split=0.123; bagging_fraction=0.836 : y = 0.932 : 57.8 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:20:42 2025 AUC 0.930567392007848\n",
      "\n",
      "[mbo] 12: num_iterations=1024; learning_rate=0.0151; feature_fraction=0.339; min_data_in_leaf=434; num_leaves=251; max_depth=9; lambda_l1=3.2; lambda_l2=4.36; min_gain_to_split=0.0703; bagging_fraction=0.837 : y = 0.931 : 58.7 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:21:40 2025 AUC 0.930511603026172\n",
      "\n",
      "[mbo] 13: num_iterations=937; learning_rate=0.015; feature_fraction=0.338; min_data_in_leaf=331; num_leaves=221; max_depth=10; lambda_l1=4.48; lambda_l2=4.36; min_gain_to_split=0.109; bagging_fraction=0.815 : y = 0.931 : 55.7 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:22:44 2025 AUC 0.930588872033355\n",
      "\n",
      "[mbo] 14: num_iterations=1003; learning_rate=0.014; feature_fraction=0.335; min_data_in_leaf=349; num_leaves=256; max_depth=10; lambda_l1=3.05; lambda_l2=4.13; min_gain_to_split=0.0942; bagging_fraction=0.886 : y = 0.931 : 62.8 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:23:44 2025 AUC 0.931501290592768\n",
      "\n",
      "[mbo] 15: num_iterations=989; learning_rate=0.0143; feature_fraction=0.342; min_data_in_leaf=353; num_leaves=211; max_depth=10; lambda_l1=4.25; lambda_l2=4.35; min_gain_to_split=0.144; bagging_fraction=0.825 : y = 0.932 : 59.0 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:24:59 2025 AUC 0.930427769988279\n",
      "\n",
      "[mbo] 16: num_iterations=1053; learning_rate=0.0118; feature_fraction=0.354; min_data_in_leaf=247; num_leaves=135; max_depth=12; lambda_l1=2.42; lambda_l2=2.92; min_gain_to_split=0.115; bagging_fraction=0.902 : y = 0.93 : 73.3 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:25:58 2025 AUC 0.930406088119405\n",
      "\n",
      "[mbo] 17: num_iterations=879; learning_rate=0.0175; feature_fraction=0.352; min_data_in_leaf=266; num_leaves=260; max_depth=11; lambda_l1=2.5; lambda_l2=3.23; min_gain_to_split=0.118; bagging_fraction=0.908 : y = 0.93 : 58.3 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:26:58 2025 AUC 0.930591298072527\n",
      "\n",
      "[mbo] 18: num_iterations=1000; learning_rate=0.0106; feature_fraction=0.352; min_data_in_leaf=352; num_leaves=256; max_depth=10; lambda_l1=4.34; lambda_l2=4.36; min_gain_to_split=0.168; bagging_fraction=0.839 : y = 0.931 : 58.8 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:27:40 2025 AUC 0.930207355070727\n",
      "\n",
      "[mbo] 19: num_iterations=669; learning_rate=0.0242; feature_fraction=0.34; min_data_in_leaf=347; num_leaves=266; max_depth=9; lambda_l1=2.82; lambda_l2=3.93; min_gain_to_split=0.107; bagging_fraction=0.897 : y = 0.93 : 40.5 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:28:32 2025 AUC 0.931376840419023\n",
      "\n",
      "[mbo] 20: num_iterations=951; learning_rate=0.0177; feature_fraction=0.313; min_data_in_leaf=395; num_leaves=166; max_depth=8; lambda_l1=3.6; lambda_l2=3.44; min_gain_to_split=0.144; bagging_fraction=0.834 : y = 0.931 : 50.8 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:29:55 2025 AUC 0.930505577652335\n",
      "\n",
      "[mbo] 21: num_iterations=1069; learning_rate=0.0129; feature_fraction=0.544; min_data_in_leaf=378; num_leaves=148; max_depth=10; lambda_l1=2.96; lambda_l2=4.09; min_gain_to_split=0.1; bagging_fraction=0.868 : y = 0.931 : 82.0 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 22 in the file bayesiana.RDATA.\n",
      "\n",
      "Thu Jul 24 21:31:06 2025 AUC 0.930633029372521\n",
      "\n",
      "[mbo] 22: num_iterations=812; learning_rate=0.0147; feature_fraction=0.461; min_data_in_leaf=206; num_leaves=186; max_depth=9; lambda_l1=2.04; lambda_l2=3.82; min_gain_to_split=0.0927; bagging_fraction=0.814 : y = 0.931 : 64.5 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:31:55 2025 AUC 0.931727212822453\n",
      "\n",
      "[mbo] 23: num_iterations=765; learning_rate=0.0187; feature_fraction=0.59; min_data_in_leaf=328; num_leaves=278; max_depth=10; lambda_l1=2.11; lambda_l2=2.7; min_gain_to_split=0.0529; bagging_fraction=0.8 : y = 0.932 : 47.9 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:32:54 2025 AUC 0.930941859145485\n",
      "\n",
      "[mbo] 24: num_iterations=986; learning_rate=0.0115; feature_fraction=0.446; min_data_in_leaf=499; num_leaves=238; max_depth=8; lambda_l1=3.74; lambda_l2=4.27; min_gain_to_split=0.147; bagging_fraction=0.811 : y = 0.931 : 57.8 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:33:56 2025 AUC 0.930690816537724\n",
      "\n",
      "[mbo] 25: num_iterations=904; learning_rate=0.0124; feature_fraction=0.512; min_data_in_leaf=497; num_leaves=192; max_depth=11; lambda_l1=3.61; lambda_l2=2.99; min_gain_to_split=0.127; bagging_fraction=0.908 : y = 0.931 : 61.3 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:34:43 2025 AUC 0.930428058303945\n",
      "\n",
      "[mbo] 26: num_iterations=777; learning_rate=0.00943; feature_fraction=0.376; min_data_in_leaf=459; num_leaves=157; max_depth=10; lambda_l1=2.55; lambda_l2=3.87; min_gain_to_split=0.0976; bagging_fraction=0.866 : y = 0.93 : 45.4 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:35:31 2025 AUC 0.930764284929171\n",
      "\n",
      "[mbo] 27: num_iterations=775; learning_rate=0.019; feature_fraction=0.485; min_data_in_leaf=383; num_leaves=263; max_depth=8; lambda_l1=2.76; lambda_l2=3.59; min_gain_to_split=0.0814; bagging_fraction=0.95 : y = 0.931 : 47.6 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:36:26 2025 AUC 0.930391501071682\n",
      "\n",
      "[mbo] 28: num_iterations=907; learning_rate=0.0164; feature_fraction=0.337; min_data_in_leaf=364; num_leaves=217; max_depth=9; lambda_l1=3.36; lambda_l2=4.36; min_gain_to_split=0.126; bagging_fraction=0.837 : y = 0.93 : 53.1 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:37:25 2025 AUC 0.931161158385745\n",
      "\n",
      "[mbo] 29: num_iterations=953; learning_rate=0.0124; feature_fraction=0.389; min_data_in_leaf=379; num_leaves=233; max_depth=9; lambda_l1=2.92; lambda_l2=3.18; min_gain_to_split=0.122; bagging_fraction=0.93 : y = 0.931 : 57.1 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:38:26 2025 AUC 0.931471640669119\n",
      "\n",
      "[mbo] 30: num_iterations=1007; learning_rate=0.016; feature_fraction=0.443; min_data_in_leaf=469; num_leaves=268; max_depth=8; lambda_l1=2.07; lambda_l2=3.06; min_gain_to_split=0.0522; bagging_fraction=0.938 : y = 0.931 : 59.9 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:39:30 2025 AUC 0.930767821294626\n",
      "\n",
      "[mbo] 31: num_iterations=988; learning_rate=0.0155; feature_fraction=0.348; min_data_in_leaf=345; num_leaves=234; max_depth=11; lambda_l1=3.91; lambda_l2=4.36; min_gain_to_split=0.0746; bagging_fraction=0.858 : y = 0.931 : 63.1 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:40:15 2025 AUC 0.929455439658507\n",
      "\n",
      "[mbo] 32: num_iterations=654; learning_rate=0.0141; feature_fraction=0.575; min_data_in_leaf=416; num_leaves=212; max_depth=12; lambda_l1=3.64; lambda_l2=2.97; min_gain_to_split=0.0885; bagging_fraction=0.848 : y = 0.929 : 43.3 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 33 in the file bayesiana.RDATA.\n",
      "\n",
      "Thu Jul 24 21:41:18 2025 AUC 0.931287543790422\n",
      "\n",
      "[mbo] 33: num_iterations=954; learning_rate=0.0183; feature_fraction=0.38; min_data_in_leaf=362; num_leaves=192; max_depth=10; lambda_l1=4.69; lambda_l2=4.29; min_gain_to_split=0.0937; bagging_fraction=0.935 : y = 0.931 : 58.2 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:42:06 2025 AUC 0.930843857687805\n",
      "\n",
      "[mbo] 34: num_iterations=655; learning_rate=0.0241; feature_fraction=0.434; min_data_in_leaf=246; num_leaves=238; max_depth=11; lambda_l1=2.51; lambda_l2=2.53; min_gain_to_split=0.0975; bagging_fraction=0.845 : y = 0.931 : 46.7 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:42:53 2025 AUC 0.930407676680922\n",
      "\n",
      "[mbo] 35: num_iterations=729; learning_rate=0.0155; feature_fraction=0.41; min_data_in_leaf=424; num_leaves=184; max_depth=10; lambda_l1=4.29; lambda_l2=4.36; min_gain_to_split=0.0648; bagging_fraction=0.854 : y = 0.93 : 45.9 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:43:41 2025 AUC 0.929659083795267\n",
      "\n",
      "[mbo] 36: num_iterations=662; learning_rate=0.0233; feature_fraction=0.351; min_data_in_leaf=204; num_leaves=189; max_depth=11; lambda_l1=2.83; lambda_l2=4.12; min_gain_to_split=0.0694; bagging_fraction=0.945 : y = 0.93 : 46.3 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:44:35 2025 AUC 0.931003440930999\n",
      "\n",
      "[mbo] 37: num_iterations=1021; learning_rate=0.0182; feature_fraction=0.324; min_data_in_leaf=260; num_leaves=278; max_depth=8; lambda_l1=3.74; lambda_l2=4.01; min_gain_to_split=0.199; bagging_fraction=0.852 : y = 0.931 : 53.0 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:45:38 2025 AUC 0.931668356582589\n",
      "\n",
      "[mbo] 38: num_iterations=999; learning_rate=0.015; feature_fraction=0.345; min_data_in_leaf=342; num_leaves=192; max_depth=10; lambda_l1=2.73; lambda_l2=4.36; min_gain_to_split=0.0588; bagging_fraction=0.842 : y = 0.932 : 61.2 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:46:40 2025 AUC 0.930706159362782\n",
      "\n",
      "[mbo] 39: num_iterations=971; learning_rate=0.0146; feature_fraction=0.338; min_data_in_leaf=352; num_leaves=250; max_depth=10; lambda_l1=3.32; lambda_l2=4.36; min_gain_to_split=0.096; bagging_fraction=0.839 : y = 0.931 : 59.5 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:47:25 2025 AUC 0.930939717398229\n",
      "\n",
      "[mbo] 40: num_iterations=748; learning_rate=0.0119; feature_fraction=0.406; min_data_in_leaf=498; num_leaves=205; max_depth=10; lambda_l1=4.2; lambda_l2=4.22; min_gain_to_split=0.176; bagging_fraction=0.873 : y = 0.931 : 44.2 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:48:24 2025 AUC 0.930933410435185\n",
      "\n",
      "[mbo] 41: num_iterations=959; learning_rate=0.0199; feature_fraction=0.369; min_data_in_leaf=310; num_leaves=245; max_depth=10; lambda_l1=4.46; lambda_l2=4.34; min_gain_to_split=0.0888; bagging_fraction=0.93 : y = 0.931 : 57.5 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:49:18 2025 AUC 0.931063524707644\n",
      "\n",
      "[mbo] 42: num_iterations=862; learning_rate=0.0229; feature_fraction=0.516; min_data_in_leaf=448; num_leaves=190; max_depth=9; lambda_l1=2.36; lambda_l2=2.53; min_gain_to_split=0.181; bagging_fraction=0.881 : y = 0.931 : 53.2 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:50:08 2025 AUC 0.929303100875983\n",
      "\n",
      "[mbo] 43: num_iterations=907; learning_rate=0.00923; feature_fraction=0.301; min_data_in_leaf=466; num_leaves=177; max_depth=9; lambda_l1=4.19; lambda_l2=3.71; min_gain_to_split=0.193; bagging_fraction=0.867 : y = 0.929 : 48.7 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:51:19 2025 AUC 0.93091868246376\n",
      "\n",
      "[mbo] 44: num_iterations=1088; learning_rate=0.0111; feature_fraction=0.396; min_data_in_leaf=467; num_leaves=211; max_depth=10; lambda_l1=3.23; lambda_l2=4.36; min_gain_to_split=0.0933; bagging_fraction=0.836 : y = 0.931 : 69.4 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 45 in the file bayesiana.RDATA.\n",
      "\n",
      "Thu Jul 24 21:52:17 2025 AUC 0.930770081582257\n",
      "\n",
      "[mbo] 45: num_iterations=962; learning_rate=0.0248; feature_fraction=0.337; min_data_in_leaf=365; num_leaves=261; max_depth=10; lambda_l1=3.6; lambda_l2=3.49; min_gain_to_split=0.115; bagging_fraction=0.835 : y = 0.931 : 52.1 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:53:19 2025 AUC 0.930926489650658\n",
      "\n",
      "[mbo] 46: num_iterations=990; learning_rate=0.0156; feature_fraction=0.319; min_data_in_leaf=356; num_leaves=234; max_depth=10; lambda_l1=2.86; lambda_l2=4.36; min_gain_to_split=0.0718; bagging_fraction=0.886 : y = 0.931 : 60.4 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:54:21 2025 AUC 0.93174515446182\n",
      "\n",
      "[mbo] 47: num_iterations=990; learning_rate=0.0143; feature_fraction=0.367; min_data_in_leaf=411; num_leaves=183; max_depth=10; lambda_l1=4.52; lambda_l2=4.02; min_gain_to_split=0.077; bagging_fraction=0.878 : y = 0.932 : 60.7 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:55:25 2025 AUC 0.931028540573588\n",
      "\n",
      "[mbo] 48: num_iterations=962; learning_rate=0.0146; feature_fraction=0.458; min_data_in_leaf=339; num_leaves=208; max_depth=10; lambda_l1=3.67; lambda_l2=4.4; min_gain_to_split=0.155; bagging_fraction=0.833 : y = 0.931 : 62.4 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:56:21 2025 AUC 0.93121626532048\n",
      "\n",
      "[mbo] 49: num_iterations=891; learning_rate=0.011; feature_fraction=0.502; min_data_in_leaf=421; num_leaves=262; max_depth=8; lambda_l1=2.21; lambda_l2=3.72; min_gain_to_split=0.0867; bagging_fraction=0.907 : y = 0.931 : 54.2 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:57:22 2025 AUC 0.930892339703964\n",
      "\n",
      "[mbo] 50: num_iterations=1007; learning_rate=0.0143; feature_fraction=0.379; min_data_in_leaf=391; num_leaves=207; max_depth=9; lambda_l1=4.37; lambda_l2=4.34; min_gain_to_split=0.0975; bagging_fraction=0.91 : y = 0.931 : 59.8 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:58:15 2025 AUC 0.930456678834445\n",
      "\n",
      "[mbo] 51: num_iterations=817; learning_rate=0.0119; feature_fraction=0.428; min_data_in_leaf=413; num_leaves=230; max_depth=10; lambda_l1=3.99; lambda_l2=3.89; min_gain_to_split=0.0516; bagging_fraction=0.919 : y = 0.93 : 51.8 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 21:59:16 2025 AUC 0.931932478338856\n",
      "\n",
      "[mbo] 52: num_iterations=953; learning_rate=0.0143; feature_fraction=0.355; min_data_in_leaf=325; num_leaves=184; max_depth=10; lambda_l1=3.23; lambda_l2=3.12; min_gain_to_split=0.0621; bagging_fraction=0.865 : y = 0.932 : 59.7 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 22:00:08 2025 AUC 0.930800393742268\n",
      "\n",
      "[mbo] 53: num_iterations=756; learning_rate=0.0129; feature_fraction=0.352; min_data_in_leaf=202; num_leaves=187; max_depth=12; lambda_l1=4.49; lambda_l2=2.64; min_gain_to_split=0.157; bagging_fraction=0.936 : y = 0.931 : 50.4 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 22:01:12 2025 AUC 0.930375493580259\n",
      "\n",
      "[mbo] 54: num_iterations=947; learning_rate=0.0131; feature_fraction=0.362; min_data_in_leaf=310; num_leaves=184; max_depth=10; lambda_l1=3.4; lambda_l2=3.33; min_gain_to_split=0.0811; bagging_fraction=0.889 : y = 0.93 : 61.9 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 22:02:07 2025 AUC 0.932267905170859\n",
      "\n",
      "[mbo] 55: num_iterations=939; learning_rate=0.0177; feature_fraction=0.343; min_data_in_leaf=498; num_leaves=237; max_depth=8; lambda_l1=3.62; lambda_l2=4.1; min_gain_to_split=0.107; bagging_fraction=0.855 : y = 0.932 : 53.2 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 56 in the file bayesiana.RDATA.\n",
      "\n",
      "Thu Jul 24 22:03:09 2025 AUC 0.931334308101069\n",
      "\n",
      "[mbo] 56: num_iterations=983; learning_rate=0.0105; feature_fraction=0.308; min_data_in_leaf=484; num_leaves=131; max_depth=9; lambda_l1=4.37; lambda_l2=4.39; min_gain_to_split=0.122; bagging_fraction=0.939 : y = 0.931 : 55.2 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 22:04:00 2025 AUC 0.92981498162783\n",
      "\n",
      "[mbo] 57: num_iterations=803; learning_rate=0.00902; feature_fraction=0.593; min_data_in_leaf=316; num_leaves=262; max_depth=10; lambda_l1=4.45; lambda_l2=2.89; min_gain_to_split=0.102; bagging_fraction=0.93 : y = 0.93 : 49.6 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 22:04:46 2025 AUC 0.930458004460619\n",
      "\n",
      "[mbo] 58: num_iterations=883; learning_rate=0.0165; feature_fraction=0.595; min_data_in_leaf=419; num_leaves=204; max_depth=8; lambda_l1=2.53; lambda_l2=3.48; min_gain_to_split=0.162; bagging_fraction=0.805 : y = 0.93 : 45.2 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 22:05:33 2025 AUC 0.930828887510472\n",
      "\n",
      "[mbo] 59: num_iterations=797; learning_rate=0.0177; feature_fraction=0.339; min_data_in_leaf=476; num_leaves=231; max_depth=8; lambda_l1=3.48; lambda_l2=3.33; min_gain_to_split=0.134; bagging_fraction=0.863 : y = 0.931 : 44.6 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 22:06:43 2025 AUC 0.9304201482941\n",
      "\n",
      "[mbo] 60: num_iterations=919; learning_rate=0.0242; feature_fraction=0.568; min_data_in_leaf=267; num_leaves=169; max_depth=11; lambda_l1=2.08; lambda_l2=3.43; min_gain_to_split=0.0512; bagging_fraction=0.943 : y = 0.93 : 69.2 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 22:07:34 2025 AUC 0.931313725142827\n",
      "\n",
      "[mbo] 61: num_iterations=824; learning_rate=0.0249; feature_fraction=0.35; min_data_in_leaf=300; num_leaves=196; max_depth=10; lambda_l1=3.52; lambda_l2=3.16; min_gain_to_split=0.106; bagging_fraction=0.823 : y = 0.931 : 48.8 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 22:08:36 2025 AUC 0.930409202704056\n",
      "\n",
      "[mbo] 62: num_iterations=1031; learning_rate=0.0155; feature_fraction=0.312; min_data_in_leaf=327; num_leaves=145; max_depth=10; lambda_l1=3.56; lambda_l2=4.36; min_gain_to_split=0.189; bagging_fraction=0.841 : y = 0.93 : 60.7 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 22:09:20 2025 AUC 0.931603368537106\n",
      "\n",
      "[mbo] 63: num_iterations=692; learning_rate=0.0188; feature_fraction=0.383; min_data_in_leaf=388; num_leaves=170; max_depth=9; lambda_l1=3.68; lambda_l2=4.11; min_gain_to_split=0.119; bagging_fraction=0.923 : y = 0.932 : 42.7 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 22:10:29 2025 AUC 0.930234294978492\n",
      "\n",
      "[mbo] 64: num_iterations=1087; learning_rate=0.0246; feature_fraction=0.473; min_data_in_leaf=377; num_leaves=254; max_depth=9; lambda_l1=2.04; lambda_l2=3.51; min_gain_to_split=0.115; bagging_fraction=0.949 : y = 0.93 : 68.0 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 22:11:30 2025 AUC 0.931632863604638\n",
      "\n",
      "[mbo] 65: num_iterations=884; learning_rate=0.0187; feature_fraction=0.555; min_data_in_leaf=476; num_leaves=262; max_depth=11; lambda_l1=3.73; lambda_l2=2.68; min_gain_to_split=0.114; bagging_fraction=0.883 : y = 0.932 : 60.1 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 22:12:25 2025 AUC 0.930555122231127\n",
      "\n",
      "[mbo] 66: num_iterations=931; learning_rate=0.0099; feature_fraction=0.315; min_data_in_leaf=494; num_leaves=138; max_depth=11; lambda_l1=4.56; lambda_l2=4.05; min_gain_to_split=0.146; bagging_fraction=0.896 : y = 0.931 : 53.7 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 67 in the file bayesiana.RDATA.\n",
      "\n",
      "Thu Jul 24 22:13:32 2025 AUC 0.931104926210403\n",
      "\n",
      "[mbo] 67: num_iterations=1037; learning_rate=0.0177; feature_fraction=0.329; min_data_in_leaf=325; num_leaves=167; max_depth=8; lambda_l1=3.67; lambda_l2=3.7; min_gain_to_split=0.104; bagging_fraction=0.86 : y = 0.931 : 58.4 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 22:14:22 2025 AUC 0.930907019693893\n",
      "\n",
      "[mbo] 68: num_iterations=709; learning_rate=0.0151; feature_fraction=0.356; min_data_in_leaf=217; num_leaves=136; max_depth=10; lambda_l1=2.47; lambda_l2=3.55; min_gain_to_split=0.0804; bagging_fraction=0.814 : y = 0.931 : 47.9 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 22:15:21 2025 AUC 0.930835177472748\n",
      "\n",
      "[mbo] 69: num_iterations=1032; learning_rate=0.0158; feature_fraction=0.351; min_data_in_leaf=373; num_leaves=209; max_depth=10; lambda_l1=4.74; lambda_l2=3.07; min_gain_to_split=0.194; bagging_fraction=0.92 : y = 0.931 : 58.4 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 22:16:20 2025 AUC 0.930587106230647\n",
      "\n",
      "[mbo] 70: num_iterations=1042; learning_rate=0.0176; feature_fraction=0.343; min_data_in_leaf=439; num_leaves=210; max_depth=8; lambda_l1=4.56; lambda_l2=3.38; min_gain_to_split=0.129; bagging_fraction=0.862 : y = 0.931 : 56.8 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 22:17:21 2025 AUC 0.930768887323891\n",
      "\n",
      "[mbo] 71: num_iterations=817; learning_rate=0.0162; feature_fraction=0.467; min_data_in_leaf=278; num_leaves=184; max_depth=10; lambda_l1=2.68; lambda_l2=3.1; min_gain_to_split=0.0613; bagging_fraction=0.863 : y = 0.931 : 58.4 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 22:18:19 2025 AUC 0.929983594887501\n",
      "\n",
      "[mbo] 72: num_iterations=913; learning_rate=0.0101; feature_fraction=0.492; min_data_in_leaf=401; num_leaves=241; max_depth=8; lambda_l1=2.81; lambda_l2=3.05; min_gain_to_split=0.133; bagging_fraction=0.884 : y = 0.93 : 56.6 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 22:19:19 2025 AUC 0.931222946482132\n",
      "\n",
      "[mbo] 73: num_iterations=932; learning_rate=0.0149; feature_fraction=0.376; min_data_in_leaf=425; num_leaves=131; max_depth=10; lambda_l1=2.55; lambda_l2=4.34; min_gain_to_split=0.172; bagging_fraction=0.81 : y = 0.931 : 59.4 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 22:20:02 2025 AUC 0.930539980574514\n",
      "\n",
      "[mbo] 74: num_iterations=676; learning_rate=0.0158; feature_fraction=0.597; min_data_in_leaf=388; num_leaves=259; max_depth=10; lambda_l1=2.64; lambda_l2=3.29; min_gain_to_split=0.128; bagging_fraction=0.8 : y = 0.931 : 41.4 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 22:20:45 2025 AUC 0.930393145204248\n",
      "\n",
      "[mbo] 75: num_iterations=747; learning_rate=0.0103; feature_fraction=0.584; min_data_in_leaf=498; num_leaves=184; max_depth=8; lambda_l1=2.7; lambda_l2=4.1; min_gain_to_split=0.0889; bagging_fraction=0.927 : y = 0.93 : 40.9 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 22:21:45 2025 AUC 0.930045487066751\n",
      "\n",
      "[mbo] 76: num_iterations=1022; learning_rate=0.00932; feature_fraction=0.358; min_data_in_leaf=429; num_leaves=218; max_depth=8; lambda_l1=3.22; lambda_l2=4.03; min_gain_to_split=0.184; bagging_fraction=0.824 : y = 0.93 : 58.0 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 22:22:49 2025 AUC 0.931543602320003\n",
      "\n",
      "[mbo] 77: num_iterations=880; learning_rate=0.0165; feature_fraction=0.504; min_data_in_leaf=221; num_leaves=277; max_depth=9; lambda_l1=3.1; lambda_l2=2.91; min_gain_to_split=0.0959; bagging_fraction=0.821 : y = 0.932 : 62.6 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 78 in the file bayesiana.RDATA.\n",
      "\n",
      "Thu Jul 24 22:23:42 2025 AUC 0.930798655720367\n",
      "\n",
      "[mbo] 78: num_iterations=824; learning_rate=0.0177; feature_fraction=0.336; min_data_in_leaf=467; num_leaves=240; max_depth=8; lambda_l1=3.58; lambda_l2=4.13; min_gain_to_split=0.116; bagging_fraction=0.826 : y = 0.931 : 45.4 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 22:24:50 2025 AUC 0.931437294674998\n",
      "\n",
      "[mbo] 79: num_iterations=1087; learning_rate=0.0166; feature_fraction=0.471; min_data_in_leaf=224; num_leaves=219; max_depth=8; lambda_l1=3.17; lambda_l2=3.73; min_gain_to_split=0.196; bagging_fraction=0.845 : y = 0.931 : 66.7 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 22:25:59 2025 AUC 0.930633719640918\n",
      "\n",
      "[mbo] 80: num_iterations=963; learning_rate=0.0132; feature_fraction=0.495; min_data_in_leaf=371; num_leaves=212; max_depth=10; lambda_l1=3.65; lambda_l2=3.81; min_gain_to_split=0.123; bagging_fraction=0.929 : y = 0.931 : 66.7 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 22:26:47 2025 AUC 0.931331071536991\n",
      "\n",
      "[mbo] 81: num_iterations=737; learning_rate=0.0158; feature_fraction=0.332; min_data_in_leaf=377; num_leaves=280; max_depth=12; lambda_l1=4.53; lambda_l2=4.14; min_gain_to_split=0.162; bagging_fraction=0.855 : y = 0.931 : 45.9 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 22:27:49 2025 AUC 0.931228763822979\n",
      "\n",
      "[mbo] 82: num_iterations=954; learning_rate=0.0146; feature_fraction=0.335; min_data_in_leaf=368; num_leaves=182; max_depth=10; lambda_l1=3.09; lambda_l2=3.44; min_gain_to_split=0.0614; bagging_fraction=0.899 : y = 0.931 : 59.8 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 22:28:52 2025 AUC 0.93169608820398\n",
      "\n",
      "[mbo] 83: num_iterations=969; learning_rate=0.0143; feature_fraction=0.423; min_data_in_leaf=355; num_leaves=245; max_depth=10; lambda_l1=4.41; lambda_l2=3.76; min_gain_to_split=0.167; bagging_fraction=0.881 : y = 0.932 : 61.1 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 22:29:36 2025 AUC 0.930033949349402\n",
      "\n",
      "[mbo] 84: num_iterations=692; learning_rate=0.0134; feature_fraction=0.47; min_data_in_leaf=270; num_leaves=269; max_depth=8; lambda_l1=3.29; lambda_l2=2.64; min_gain_to_split=0.161; bagging_fraction=0.81 : y = 0.93 : 42.8 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 22:30:43 2025 AUC 0.930104175905279\n",
      "\n",
      "[mbo] 85: num_iterations=1043; learning_rate=0.024; feature_fraction=0.506; min_data_in_leaf=451; num_leaves=211; max_depth=11; lambda_l1=3.99; lambda_l2=2.65; min_gain_to_split=0.0753; bagging_fraction=0.8 : y = 0.93 : 65.3 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 22:31:32 2025 AUC 0.930600650559778\n",
      "\n",
      "[mbo] 86: num_iterations=823; learning_rate=0.0245; feature_fraction=0.381; min_data_in_leaf=351; num_leaves=180; max_depth=10; lambda_l1=3.81; lambda_l2=4.06; min_gain_to_split=0.173; bagging_fraction=0.903 : y = 0.931 : 48.1 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 22:32:22 2025 AUC 0.930366374709244\n",
      "\n",
      "[mbo] 87: num_iterations=732; learning_rate=0.0143; feature_fraction=0.435; min_data_in_leaf=352; num_leaves=185; max_depth=10; lambda_l1=3.96; lambda_l2=2.97; min_gain_to_split=0.17; bagging_fraction=0.862 : y = 0.93 : 48.3 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 22:33:18 2025 AUC 0.931649002427619\n",
      "\n",
      "[mbo] 88: num_iterations=945; learning_rate=0.0135; feature_fraction=0.323; min_data_in_leaf=241; num_leaves=271; max_depth=8; lambda_l1=4.25; lambda_l2=2.76; min_gain_to_split=0.182; bagging_fraction=0.907 : y = 0.932 : 53.8 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 89 in the file bayesiana.RDATA.\n",
      "\n",
      "Thu Jul 24 22:34:17 2025 AUC 0.930994094564678\n",
      "\n",
      "[mbo] 89: num_iterations=941; learning_rate=0.0238; feature_fraction=0.321; min_data_in_leaf=285; num_leaves=187; max_depth=11; lambda_l1=3.61; lambda_l2=4.15; min_gain_to_split=0.128; bagging_fraction=0.809 : y = 0.931 : 51.4 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 22:35:18 2025 AUC 0.930447036640608\n",
      "\n",
      "[mbo] 90: num_iterations=953; learning_rate=0.0144; feature_fraction=0.316; min_data_in_leaf=278; num_leaves=184; max_depth=10; lambda_l1=2.4; lambda_l2=3.57; min_gain_to_split=0.158; bagging_fraction=0.867 : y = 0.93 : 59.1 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 22:36:03 2025 AUC 0.930752059219636\n",
      "\n",
      "[mbo] 91: num_iterations=664; learning_rate=0.0201; feature_fraction=0.459; min_data_in_leaf=330; num_leaves=248; max_depth=11; lambda_l1=4.87; lambda_l2=2.99; min_gain_to_split=0.17; bagging_fraction=0.811 : y = 0.931 : 42.9 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 22:37:13 2025 AUC 0.930836452773322\n",
      "\n",
      "[mbo] 92: num_iterations=966; learning_rate=0.0143; feature_fraction=0.507; min_data_in_leaf=447; num_leaves=217; max_depth=11; lambda_l1=3.51; lambda_l2=2.99; min_gain_to_split=0.0616; bagging_fraction=0.839 : y = 0.931 : 67.6 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 22:38:05 2025 AUC 0.930768258784269\n",
      "\n",
      "[mbo] 93: num_iterations=804; learning_rate=0.0241; feature_fraction=0.453; min_data_in_leaf=413; num_leaves=201; max_depth=9; lambda_l1=4.64; lambda_l2=3.63; min_gain_to_split=0.0695; bagging_fraction=0.864 : y = 0.931 : 50.7 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 22:39:03 2025 AUC 0.930295758688003\n",
      "\n",
      "[mbo] 94: num_iterations=951; learning_rate=0.0176; feature_fraction=0.35; min_data_in_leaf=394; num_leaves=258; max_depth=10; lambda_l1=3.62; lambda_l2=4.1; min_gain_to_split=0.188; bagging_fraction=0.93 : y = 0.93 : 55.6 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 22:39:57 2025 AUC 0.931915780274138\n",
      "\n",
      "[mbo] 95: num_iterations=860; learning_rate=0.014; feature_fraction=0.341; min_data_in_leaf=313; num_leaves=200; max_depth=9; lambda_l1=3.02; lambda_l2=3.14; min_gain_to_split=0.0621; bagging_fraction=0.831 : y = 0.932 : 51.7 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 22:40:49 2025 AUC 0.930952340295624\n",
      "\n",
      "[mbo] 96: num_iterations=838; learning_rate=0.0137; feature_fraction=0.404; min_data_in_leaf=374; num_leaves=249; max_depth=9; lambda_l1=3.29; lambda_l2=3.23; min_gain_to_split=0.159; bagging_fraction=0.948 : y = 0.931 : 50.8 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 22:41:45 2025 AUC 0.93042783666746\n",
      "\n",
      "[mbo] 97: num_iterations=938; learning_rate=0.0177; feature_fraction=0.339; min_data_in_leaf=387; num_leaves=200; max_depth=9; lambda_l1=3.82; lambda_l2=3.9; min_gain_to_split=0.166; bagging_fraction=0.852 : y = 0.93 : 53.4 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 22:42:46 2025 AUC 0.930010009956073\n",
      "\n",
      "[mbo] 98: num_iterations=868; learning_rate=0.0115; feature_fraction=0.508; min_data_in_leaf=303; num_leaves=167; max_depth=9; lambda_l1=3.05; lambda_l2=3.07; min_gain_to_split=0.0552; bagging_fraction=0.87 : y = 0.93 : 58.0 secs : infill_ei\n",
      "\n",
      "Thu Jul 24 22:43:25 2025 AUC 0.931327379808413\n",
      "\n",
      "[mbo] 99: num_iterations=672; learning_rate=0.0136; feature_fraction=0.336; min_data_in_leaf=257; num_leaves=237; max_depth=8; lambda_l1=4.67; lambda_l2=4.4; min_gain_to_split=0.117; bagging_fraction=0.873 : y = 0.931 : 37.8 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 100 in the file bayesiana.RDATA.\n",
      "\n",
      "Thu Jul 24 22:44:30 2025 AUC 0.930015041955886\n",
      "\n",
      "[mbo] 100: num_iterations=985; learning_rate=0.0141; feature_fraction=0.365; min_data_in_leaf=320; num_leaves=197; max_depth=9; lambda_l1=3.1; lambda_l2=3.11; min_gain_to_split=0.0745; bagging_fraction=0.896 : y = 0.93 : 59.2 secs : infill_ei\n",
      "\n",
      "Saved the final state in the file bayesiana.RDATA\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# inicio la optimizacion bayesiana, retomando si ya existe\n",
    "# es la celda mas lenta de todo el notebook\n",
    "\n",
    "if (!file.exists(kbayesiana)) {\n",
    "  bayesiana_salida <- mbo(obj.fun, learner= surr.km, control= ctrl)\n",
    "} else {\n",
    "  bayesiana_salida <- mboContinue(kbayesiana) # retomo en caso que ya exista\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ssk5nnMk6INK"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'num_iterations'</li><li>'learning_rate'</li><li>'feature_fraction'</li><li>'min_data_in_leaf'</li><li>'num_leaves'</li><li>'max_depth'</li><li>'lambda_l1'</li><li>'lambda_l2'</li><li>'min_gain_to_split'</li><li>'bagging_fraction'</li><li>'y'</li><li>'dob'</li><li>'eol'</li><li>'error.message'</li><li>'exec.time'</li><li>'ei'</li><li>'error.model'</li><li>'train.time'</li><li>'prop.type'</li><li>'propose.time'</li><li>'se'</li><li>'mean'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'num\\_iterations'\n",
       "\\item 'learning\\_rate'\n",
       "\\item 'feature\\_fraction'\n",
       "\\item 'min\\_data\\_in\\_leaf'\n",
       "\\item 'num\\_leaves'\n",
       "\\item 'max\\_depth'\n",
       "\\item 'lambda\\_l1'\n",
       "\\item 'lambda\\_l2'\n",
       "\\item 'min\\_gain\\_to\\_split'\n",
       "\\item 'bagging\\_fraction'\n",
       "\\item 'y'\n",
       "\\item 'dob'\n",
       "\\item 'eol'\n",
       "\\item 'error.message'\n",
       "\\item 'exec.time'\n",
       "\\item 'ei'\n",
       "\\item 'error.model'\n",
       "\\item 'train.time'\n",
       "\\item 'prop.type'\n",
       "\\item 'propose.time'\n",
       "\\item 'se'\n",
       "\\item 'mean'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'num_iterations'\n",
       "2. 'learning_rate'\n",
       "3. 'feature_fraction'\n",
       "4. 'min_data_in_leaf'\n",
       "5. 'num_leaves'\n",
       "6. 'max_depth'\n",
       "7. 'lambda_l1'\n",
       "8. 'lambda_l2'\n",
       "9. 'min_gain_to_split'\n",
       "10. 'bagging_fraction'\n",
       "11. 'y'\n",
       "12. 'dob'\n",
       "13. 'eol'\n",
       "14. 'error.message'\n",
       "15. 'exec.time'\n",
       "16. 'ei'\n",
       "17. 'error.model'\n",
       "18. 'train.time'\n",
       "19. 'prop.type'\n",
       "20. 'propose.time'\n",
       "21. 'se'\n",
       "22. 'mean'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"num_iterations\"    \"learning_rate\"     \"feature_fraction\" \n",
       " [4] \"min_data_in_leaf\"  \"num_leaves\"        \"max_depth\"        \n",
       " [7] \"lambda_l1\"         \"lambda_l2\"         \"min_gain_to_split\"\n",
       "[10] \"bagging_fraction\"  \"y\"                 \"dob\"              \n",
       "[13] \"eol\"               \"error.message\"     \"exec.time\"        \n",
       "[16] \"ei\"                \"error.model\"       \"train.time\"       \n",
       "[19] \"prop.type\"         \"propose.time\"      \"se\"               \n",
       "[22] \"mean\"             "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "tb_bayesiana <- as.data.table(bayesiana_salida$opt.path)\n",
    "colnames( tb_bayesiana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "u4zq-vknhjGc"
   },
   "outputs": [],
   "source": [
    "# almaceno los resultados de la Bayesian Optimization\n",
    "# y capturo los mejores hiperparametros encontrados\n",
    "\n",
    "tb_bayesiana <- as.data.table(bayesiana_salida$opt.path)\n",
    "\n",
    "tb_bayesiana[, iter := .I]\n",
    "\n",
    "# ordeno en forma descendente por AUC = y\n",
    "setorder(tb_bayesiana, -y)\n",
    "\n",
    "# grabo para eventualmente poder utilizarlos en OTRA corrida\n",
    "fwrite( tb_bayesiana,\n",
    "  file= \"BO_log.txt\",\n",
    "  sep= \"\\t\"\n",
    ")\n",
    "\n",
    "# los mejores hiperparámetros son los que quedaron en el registro 1 de la tabla\n",
    "PARAM$out$lgbm$mejores_hiperparametros <- tb_bayesiana[\n",
    "  1, # el primero es el de mejor AUC\n",
    "  setdiff(colnames(tb_bayesiana),\n",
    "    c(\"y\",\"dob\",\"eol\",\"error.message\",\"exec.time\",\"ei\",\"error.model\",\n",
    "      \"train.time\",\"prop.type\",\"propose.time\",\"se\",\"mean\",\"iter\")),\n",
    "  with= FALSE\n",
    "]\n",
    "\n",
    "\n",
    "PARAM$out$lgbm$y <- tb_bayesiana[1, y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E8v2eA427N8e"
   },
   "outputs": [],
   "source": [
    "write_yaml( PARAM, file=\"PARAM.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iBTWexVU7PGC"
   },
   "outputs": [],
   "source": [
    "print(PARAM$out$lgbm$mejores_hiperparametros)\n",
    "print(PARAM$out$lgbm$y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TKsVZmAnhwX-"
   },
   "source": [
    "## 2.3  Produccion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQ_C33Tr5B_9"
   },
   "source": [
    "### Final Training\n",
    "Construyo el modelo final, que es uno solo, no hace ningun tipo de particion < training, validation, testing>]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "eDqfyA14hzwv"
   },
   "outputs": [],
   "source": [
    "setwd(\"/content/buckets/b1/exp\")\n",
    "experimento <- paste0(\"exp\", PARAM$experimento)\n",
    "dir.create(experimento, showWarnings= FALSE)\n",
    "setwd( paste0(\"/content/buckets/b1/exp/\", experimento ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8qFmFivf5Iet"
   },
   "source": [
    "#### Final Training Dataset\n",
    "\n",
    "Aqui esta la gran decision de en qué meses hago el Final Training\n",
    "<br> debo utilizar los mejores hiperparámetros que encontré en la optimización bayesiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "lg5WVZncvc7H"
   },
   "outputs": [],
   "source": [
    "# clase01\n",
    "dataset[, clase01 := ifelse(clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\"), 1L, 0L)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "yc9QzXREv0xf"
   },
   "outputs": [],
   "source": [
    "dataset_train <- dataset[foto_mes %in% c(202107)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "thjdqEBLuvNt"
   },
   "outputs": [],
   "source": [
    "# dejo los datos en el formato que necesita LightGBM\n",
    "\n",
    "dtrain <- lgb.Dataset(\n",
    "  data= data.matrix(dataset_train[, campos_buenos, with= FALSE]),\n",
    "  label= dataset_train[, clase01]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNUa-WSz5Oqu"
   },
   "source": [
    "#### Final Training Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "FgCcvBfEwImu"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$boosting</dt>\n",
       "\t\t<dd>'gbdt'</dd>\n",
       "\t<dt>$objective</dt>\n",
       "\t\t<dd>'binary'</dd>\n",
       "\t<dt>$metric</dt>\n",
       "\t\t<dd>'auc'</dd>\n",
       "\t<dt>$first_metric_only</dt>\n",
       "\t\t<dd>FALSE</dd>\n",
       "\t<dt>$boost_from_average</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>$feature_pre_filter</dt>\n",
       "\t\t<dd>FALSE</dd>\n",
       "\t<dt>$force_row_wise</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>$verbosity</dt>\n",
       "\t\t<dd>-100</dd>\n",
       "\t<dt>$seed</dt>\n",
       "\t\t<dd>100129</dd>\n",
       "\t<dt>$max_depth</dt>\n",
       "\t\t<dd>8</dd>\n",
       "\t<dt>$min_gain_to_split</dt>\n",
       "\t\t<dd>0.107300310230806</dd>\n",
       "\t<dt>$min_sum_hessian_in_leaf</dt>\n",
       "\t\t<dd>0.001</dd>\n",
       "\t<dt>$lambda_l1</dt>\n",
       "\t\t<dd>3.62323771713964</dd>\n",
       "\t<dt>$lambda_l2</dt>\n",
       "\t\t<dd>4.09689338782705</dd>\n",
       "\t<dt>$max_bin</dt>\n",
       "\t\t<dd>31</dd>\n",
       "\t<dt>$bagging_fraction</dt>\n",
       "\t\t<dd>0.855389253021384</dd>\n",
       "\t<dt>$pos_bagging_fraction</dt>\n",
       "\t\t<dd>1</dd>\n",
       "\t<dt>$neg_bagging_fraction</dt>\n",
       "\t\t<dd>1</dd>\n",
       "\t<dt>$is_unbalance</dt>\n",
       "\t\t<dd>FALSE</dd>\n",
       "\t<dt>$scale_pos_weight</dt>\n",
       "\t\t<dd>1</dd>\n",
       "\t<dt>$drop_rate</dt>\n",
       "\t\t<dd>0.1</dd>\n",
       "\t<dt>$max_drop</dt>\n",
       "\t\t<dd>50</dd>\n",
       "\t<dt>$skip_drop</dt>\n",
       "\t\t<dd>0.5</dd>\n",
       "\t<dt>$extra_trees</dt>\n",
       "\t\t<dd>FALSE</dd>\n",
       "\t<dt>$num_iterations</dt>\n",
       "\t\t<dd>939</dd>\n",
       "\t<dt>$learning_rate</dt>\n",
       "\t\t<dd>0.0176524555434714</dd>\n",
       "\t<dt>$feature_fraction</dt>\n",
       "\t\t<dd>0.343069936502526</dd>\n",
       "\t<dt>$num_leaves</dt>\n",
       "\t\t<dd>237</dd>\n",
       "\t<dt>$min_data_in_leaf</dt>\n",
       "\t\t<dd>498</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$boosting] 'gbdt'\n",
       "\\item[\\$objective] 'binary'\n",
       "\\item[\\$metric] 'auc'\n",
       "\\item[\\$first\\_metric\\_only] FALSE\n",
       "\\item[\\$boost\\_from\\_average] TRUE\n",
       "\\item[\\$feature\\_pre\\_filter] FALSE\n",
       "\\item[\\$force\\_row\\_wise] TRUE\n",
       "\\item[\\$verbosity] -100\n",
       "\\item[\\$seed] 100129\n",
       "\\item[\\$max\\_depth] 8\n",
       "\\item[\\$min\\_gain\\_to\\_split] 0.107300310230806\n",
       "\\item[\\$min\\_sum\\_hessian\\_in\\_leaf] 0.001\n",
       "\\item[\\$lambda\\_l1] 3.62323771713964\n",
       "\\item[\\$lambda\\_l2] 4.09689338782705\n",
       "\\item[\\$max\\_bin] 31\n",
       "\\item[\\$bagging\\_fraction] 0.855389253021384\n",
       "\\item[\\$pos\\_bagging\\_fraction] 1\n",
       "\\item[\\$neg\\_bagging\\_fraction] 1\n",
       "\\item[\\$is\\_unbalance] FALSE\n",
       "\\item[\\$scale\\_pos\\_weight] 1\n",
       "\\item[\\$drop\\_rate] 0.1\n",
       "\\item[\\$max\\_drop] 50\n",
       "\\item[\\$skip\\_drop] 0.5\n",
       "\\item[\\$extra\\_trees] FALSE\n",
       "\\item[\\$num\\_iterations] 939\n",
       "\\item[\\$learning\\_rate] 0.0176524555434714\n",
       "\\item[\\$feature\\_fraction] 0.343069936502526\n",
       "\\item[\\$num\\_leaves] 237\n",
       "\\item[\\$min\\_data\\_in\\_leaf] 498\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$boosting\n",
       ":   'gbdt'\n",
       "$objective\n",
       ":   'binary'\n",
       "$metric\n",
       ":   'auc'\n",
       "$first_metric_only\n",
       ":   FALSE\n",
       "$boost_from_average\n",
       ":   TRUE\n",
       "$feature_pre_filter\n",
       ":   FALSE\n",
       "$force_row_wise\n",
       ":   TRUE\n",
       "$verbosity\n",
       ":   -100\n",
       "$seed\n",
       ":   100129\n",
       "$max_depth\n",
       ":   8\n",
       "$min_gain_to_split\n",
       ":   0.107300310230806\n",
       "$min_sum_hessian_in_leaf\n",
       ":   0.001\n",
       "$lambda_l1\n",
       ":   3.62323771713964\n",
       "$lambda_l2\n",
       ":   4.09689338782705\n",
       "$max_bin\n",
       ":   31\n",
       "$bagging_fraction\n",
       ":   0.855389253021384\n",
       "$pos_bagging_fraction\n",
       ":   1\n",
       "$neg_bagging_fraction\n",
       ":   1\n",
       "$is_unbalance\n",
       ":   FALSE\n",
       "$scale_pos_weight\n",
       ":   1\n",
       "$drop_rate\n",
       ":   0.1\n",
       "$max_drop\n",
       ":   50\n",
       "$skip_drop\n",
       ":   0.5\n",
       "$extra_trees\n",
       ":   FALSE\n",
       "$num_iterations\n",
       ":   939\n",
       "$learning_rate\n",
       ":   0.0176524555434714\n",
       "$feature_fraction\n",
       ":   0.343069936502526\n",
       "$num_leaves\n",
       ":   237\n",
       "$min_data_in_leaf\n",
       ":   498\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$boosting\n",
       "[1] \"gbdt\"\n",
       "\n",
       "$objective\n",
       "[1] \"binary\"\n",
       "\n",
       "$metric\n",
       "[1] \"auc\"\n",
       "\n",
       "$first_metric_only\n",
       "[1] FALSE\n",
       "\n",
       "$boost_from_average\n",
       "[1] TRUE\n",
       "\n",
       "$feature_pre_filter\n",
       "[1] FALSE\n",
       "\n",
       "$force_row_wise\n",
       "[1] TRUE\n",
       "\n",
       "$verbosity\n",
       "[1] -100\n",
       "\n",
       "$seed\n",
       "[1] 100129\n",
       "\n",
       "$max_depth\n",
       "[1] 8\n",
       "\n",
       "$min_gain_to_split\n",
       "[1] 0.1073003\n",
       "\n",
       "$min_sum_hessian_in_leaf\n",
       "[1] 0.001\n",
       "\n",
       "$lambda_l1\n",
       "[1] 3.623238\n",
       "\n",
       "$lambda_l2\n",
       "[1] 4.096893\n",
       "\n",
       "$max_bin\n",
       "[1] 31\n",
       "\n",
       "$bagging_fraction\n",
       "[1] 0.8553893\n",
       "\n",
       "$pos_bagging_fraction\n",
       "[1] 1\n",
       "\n",
       "$neg_bagging_fraction\n",
       "[1] 1\n",
       "\n",
       "$is_unbalance\n",
       "[1] FALSE\n",
       "\n",
       "$scale_pos_weight\n",
       "[1] 1\n",
       "\n",
       "$drop_rate\n",
       "[1] 0.1\n",
       "\n",
       "$max_drop\n",
       "[1] 50\n",
       "\n",
       "$skip_drop\n",
       "[1] 0.5\n",
       "\n",
       "$extra_trees\n",
       "[1] FALSE\n",
       "\n",
       "$num_iterations\n",
       "[1] 939\n",
       "\n",
       "$learning_rate\n",
       "[1] 0.01765246\n",
       "\n",
       "$feature_fraction\n",
       "[1] 0.3430699\n",
       "\n",
       "$num_leaves\n",
       "[1] 237\n",
       "\n",
       "$min_data_in_leaf\n",
       "[1] 498\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "param_final <- modifyList(PARAM$lgbm$param_fijos,\n",
    "  PARAM$out$lgbm$mejores_hiperparametros)\n",
    "\n",
    "param_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZIYn4l95TBH"
   },
   "source": [
    "#### Training\n",
    "Genero el modelo final, siempre sobre TODOS los datos de  final_train, sin hacer ningun tipo de undersampling de la clase mayoritaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "vPLsd4mMRe4u"
   },
   "outputs": [],
   "source": [
    "# este punto es muy SUTIL  y será revisado en la Clase 05\n",
    "\n",
    "param_normalizado <- copy(param_final)\n",
    "param_normalizado$min_data_in_leaf <-  param_final$min_data_in_leaf / PARAM$trainingstrategy$undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "WRI_-taRwOXO"
   },
   "outputs": [],
   "source": [
    "  # entreno LightGBM\n",
    "\n",
    "  modelo_final <- lgb.train(\n",
    "    data= dtrain,\n",
    "    param= param_normalizado\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "_bkhnCvj0g3Q"
   },
   "outputs": [],
   "source": [
    "# ahora imprimo la importancia de variables\n",
    "\n",
    "tb_importancia <- as.data.table(lgb.importance(modelo_final))\n",
    "archivo_importancia <- \"impo.txt\"\n",
    "\n",
    "fwrite(tb_importancia,\n",
    "  file= archivo_importancia,\n",
    "  sep= \"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "lZ3sLmbh0kFj"
   },
   "outputs": [],
   "source": [
    "# grabo a disco el modelo en un formato para seres humanos ... ponele ...\n",
    "\n",
    "lgb.save(modelo_final, \"modelo.txt\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEtp2--t5Ymg"
   },
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hI5008Mj5ZdI"
   },
   "source": [
    "Aplico el modelo final a los datos del futuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "PimBY3N_0ryP"
   },
   "outputs": [],
   "source": [
    "# aplico el modelo a los datos sin clase\n",
    "dfuture <- dataset[foto_mes == 202109]\n",
    "\n",
    "# aplico el modelo a los datos nuevos\n",
    "prediccion <- predict(\n",
    "  modelo_final,\n",
    "  data.matrix(dfuture[, campos_buenos, with= FALSE])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D26rNRh55gpw"
   },
   "source": [
    "#### Tabla Prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RJwg7LHd11yu"
   },
   "outputs": [],
   "source": [
    "# tabla de prediccion\n",
    "\n",
    "tb_prediccion <- dfuture[, list(numero_de_cliente)]\n",
    "tb_prediccion[, prob := prediccion ]\n",
    "\n",
    "# grabo las probabilidad del modelo\n",
    "fwrite(tb_prediccion,\n",
    "  file= \"prediccion.txt\",\n",
    "  sep= \"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOt4eG_55ltv"
   },
   "source": [
    "Kaggle Competition Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gWW3tatE12je"
   },
   "outputs": [],
   "source": [
    "# genero archivos con los  \"envios\" mejores\n",
    "# suba TODOS los archivos a Kaggle\n",
    "\n",
    "# ordeno por probabilidad descendente\n",
    "setorder(tb_prediccion, -prob)\n",
    "\n",
    "dir.create(\"kaggle\")\n",
    "\n",
    "for (envios in PARAM$kaggle$cortes) {\n",
    "\n",
    "  tb_prediccion[, Predicted := 0L] # seteo inicial a 0\n",
    "  tb_prediccion[1:envios, Predicted := 1L] # marclo los primeros\n",
    "\n",
    "  archivo_kaggle <- paste0(\"./kaggle/KA\", PARAM$experimento, \"_\", envios, \".csv\")\n",
    "\n",
    "  # grabo el archivo\n",
    "  fwrite(tb_prediccion[, list(numero_de_cliente, Predicted)],\n",
    "    file= archivo_kaggle,\n",
    "    sep= \",\"\n",
    "  )\n",
    "\n",
    "  # subida a Kaggle, armo la linea de comando\n",
    "  comando <- \"kaggle competitions submit\"\n",
    "  competencia <- paste(\"-c\", PARAM$kaggle$competencia)\n",
    "  arch <- paste( \"-f\", archivo_kaggle)\n",
    "\n",
    "  mensaje <- paste0(\"-m 'envios=\", envios,\n",
    "  \"  semilla=\", PARAM$semilla_primigenia,\n",
    "    \"'\" )\n",
    "\n",
    "  linea <- paste( comando, competencia, arch, mensaje)\n",
    "\n",
    "  salida <- system(linea, intern=TRUE) # el submit a Kaggle\n",
    "  cat(salida, \"\\n\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B9tB2X4439Hg"
   },
   "outputs": [],
   "source": [
    "write_yaml( PARAM, file=\"PARAM.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9zA_W25c15DP"
   },
   "outputs": [],
   "source": [
    "format(Sys.time(), \"%a %b %d %X %Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UdVZucdLHzZ0"
   },
   "source": [
    "Finalmente usted deberá cargar el resultado de su corrida en la Google Sheet Colaborativa,  hoja **TareaHogar04**\n",
    "<br> Siéntase libre de agregar las columnas que hagan falta a la planilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WMHh7uNVIJkT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
